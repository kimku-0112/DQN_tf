{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train(defalt reward)\n",
    "from time import time \n",
    "import random\n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "from DQN_agent import DQN\n",
    "import gym\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default\n",
    "def main(): \n",
    "    # DQN agent constant / hyperparameter\n",
    "    RHO=0.9 \n",
    "    LAMDA=0.99\n",
    "    EPSILON=0.9\n",
    "    EPSILON_DECAY=0.999\n",
    "    EPSILON_MIN=0.01\n",
    "    BATCH_SIZE=64\n",
    "    REPLY_MEMORY_SIZE=100_000\n",
    "    N_EPISODE=1000\n",
    "    SAMPLE_RATE=1\n",
    "    TEMP_FOLDER='./temp/'\n",
    "    MODEL_FOLDER='./model/cartpole/'\n",
    "\n",
    "    # gym enviroment const / hyperparameter\n",
    "    ENV_NAME='CartPole-v1'\n",
    "    RENDER_MODE='rgb_array'\n",
    "    ENV_MAX_EPISODE_STEPS = 1000\n",
    "\n",
    "    # set random seed\n",
    "    RANDOM_SEED=112\n",
    "    set_random_seed(RANDOM_SEED)\n",
    "\n",
    "    # make & set gym enviroment\n",
    "    env=gym.make(ENV_NAME,render_mode=RENDER_MODE)\n",
    "    # env._max_episode_steps = ENV_MAX_EPISODE_STEPS \n",
    "\n",
    "    # make DQN agent\n",
    "    dqn=DQN(env,rho=RHO,lamda=LAMDA,epsilon=EPSILON,epsilon_decay_rate=EPSILON_DECAY,epsilon_min=EPSILON_MIN,batch_size=BATCH_SIZE,\n",
    "            reply_memory_size=REPLY_MEMORY_SIZE,n_episode=N_EPISODE,sample_rate=SAMPLE_RATE,\n",
    "            temp_folder=TEMP_FOLDER,model_folder=MODEL_FOLDER)\n",
    "    dqn.train()\n",
    "    dqn.save_model(dqn.model_folder+'DQN.h5')\n",
    "    env.close()\n",
    "    dqn.score_plot()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
